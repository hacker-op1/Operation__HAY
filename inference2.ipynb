{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a33a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11a563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=14, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\harsh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 14) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed09b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.load_state_dict(torch.load(\"try2.pth\"))\n",
    "net.eval()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef5bb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter directory:C:\\Users\\harsh\\Desktop\\number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.56s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00, 751.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 752.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 997.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1503.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path=input(\"please enter directory:\")\n",
    "myPicList= os.listdir(path)\n",
    "images=[]\n",
    "for y in (myPicList):\n",
    "    try:\n",
    "        img=cv2.imread(path + str('/')+y,0)\n",
    "        img = cv2.resize(img,(150,50))\n",
    "        images.append(img)\n",
    "    except:\n",
    "        pass\n",
    "images = np.array(images)\n",
    "predicted = []\n",
    "for z in range (images.shape[0]):\n",
    "    new=[]\n",
    "    new.append(images[z][0:images.shape[1] , 0: int(images.shape[2]/3)])\n",
    "    new.append(images[z][0:images.shape[1] , int(images.shape[2]/3) : int(2*int(images.shape[2]/3))])\n",
    "    new.append(images[z][0:images.shape[1] , int(2*int(images.shape[2]/3)): images.shape[2]])\n",
    "    new = torch.Tensor(new)\n",
    "    new = (new/255)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(new))):\n",
    "            net_out = net(new[i].view(-1,1,50,50).to(device))[0] \n",
    "            predicted_class = torch.argmax(net_out)\n",
    "            predicted.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378611fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arth(l):\n",
    "    try:\n",
    "        if l[0].item()>9:\n",
    "            if l[0].item()== 10:\n",
    "                return (\"prefix\",l[1].item()+l[2].item())\n",
    "            if l[0].item()== 11:\n",
    "                return (\"prefix\",l[1].item()-l[2].item())\n",
    "            if l[0].item()== 12:\n",
    "                return (\"prefix\",l[1].item()*l[2].item())\n",
    "            if l[0].item()== 13:\n",
    "                return (\"prefix\",l[1].item()/l[2].item())\n",
    "        elif l[1].item()>9:\n",
    "            if l[1].item()== 10:\n",
    "                return (\"infix\",l[0].item()+l[2].item())\n",
    "            if l[1].item()== 11:\n",
    "                return (\"infix\",l[0].item()-l[2].item())\n",
    "            if l[1].item()== 12:\n",
    "                return (\"infix\",l[0].item()*l[2].item())\n",
    "            if l[1].item()== 13:\n",
    "                return (\"infix\",l[0].item()/l[2].item())\n",
    "        elif l[2].item()>9:\n",
    "            if l[2].item()== 10:\n",
    "                return (\"postfix\",l[0].item()+l[1].item())\n",
    "            if l[2].item()== 11:\n",
    "                return (\"postfix\",l[0].item()-l[1].item())\n",
    "            if l[2].item()== 12:\n",
    "                return (\"postfix\",l[0].item()*l[1].item())\n",
    "            if l[2].item()== 13:\n",
    "                return (\"postfix\",l[0].item()/l[1].item())\n",
    "        else:\n",
    "            return (\"dk\",-100)\n",
    "    except:\n",
    "        if l[0].item()>9:\n",
    "                return (\"prefix\",-100)\n",
    "        elif l[1].item()>9:\n",
    "            return (\"infix\",-100)\n",
    "        elif l[2].item()>9:\n",
    "            return (\"postfix\",-100)\n",
    "        else:\n",
    "            return (\"dk\",-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1a8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outlab = []\n",
    "for i in range(0,len(predicted),3):\n",
    "    ans_label,answer = arth(predicted[i:i+3])\n",
    "    answer = int(answer)\n",
    "    outputs.append(answer)\n",
    "    outlab.append(ans_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "174a4da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8\n",
      "0\n",
      "21\n",
      "40\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs)):\n",
    "    print(outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af083b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(outputs, index =myPicList,columns =['Value'])\n",
    "df.to_csv('team_name_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07062b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
